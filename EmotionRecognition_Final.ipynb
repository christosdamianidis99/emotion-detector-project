{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcac852d-5720-4fb2-88c2-e593b2835ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 1. Imports and Setup\n",
    "# This cell imports necessary libraries and defines configuration parameters\n",
    "# for the project, including file paths, audio processing settings,\n",
    "# and random seeds for reproducibility.\n",
    "\n",
    "import os\n",
    "import re\n",
    "import sys # To print Python version\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import class_weight\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GaussianNoise, Layer, Reshape, Bidirectional, LSTM\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt # For evaluation plots\n",
    "import seaborn as sns # For confusion matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import sounddevice as sd # For live demo\n",
    "import soundfile as sf # For live demo\n",
    "import time # For live demo\n",
    "\n",
    "# --- Configuration ---\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Define dataset paths (UPDATE THESE if needed)\n",
    "ravdess_path = r'C:\\Code\\Python\\data\\RAVDESS'\n",
    "crema_d_path = r'C:\\Code\\Python\\data\\CREMA-D\\AudioWAV'\n",
    "iemocap_path = r'C:\\Code\\Python\\data\\IEMOCAP\\IEMOCAP_full_release'\n",
    "\n",
    "# Define audio processing parameters (Must match Flutter app)\n",
    "SR = 22050           # Sample Rate\n",
    "N_FFT = 2048         # FFT window size\n",
    "HOP_LENGTH = 512     # Hop length for STFT\n",
    "N_FREQ_BINS = 128    # Number of frequency bins to keep\n",
    "MAX_PAD_LEN = 130    # Fixed length for spectrogram time axis\n",
    "\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2e98f6-862f-4a65-819a-9a7b1bd95961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Data Loading...\n",
      "Processing RAVDESS...\n",
      "Found 1344 RAVDESS files.\n",
      "\n",
      "Processing CREMA-D...\n",
      "Found 4900 CREMA-D files.\n",
      "\n",
      "Processing IEMOCAP...\n",
      "Found 5531 IEMOCAP files.\n",
      "\n",
      "Total audio files from all datasets: 11775\n",
      "\n",
      "Final emotion distribution:\n",
      "emotion\n",
      "happy      3291\n",
      "neutral    2987\n",
      "angry      2758\n",
      "sad        2739\n",
      "Name: count, dtype: int64\n",
      "\n",
      "First 5 rows of final data:\n",
      "                                           file_path  emotion\n",
      "0  C:\\Code\\Python\\data\\RAVDESS\\Actor_01\\03-01-01-...  neutral\n",
      "1  C:\\Code\\Python\\data\\RAVDESS\\Actor_01\\03-01-01-...  neutral\n",
      "2  C:\\Code\\Python\\data\\RAVDESS\\Actor_01\\03-01-01-...  neutral\n",
      "3  C:\\Code\\Python\\data\\RAVDESS\\Actor_01\\03-01-01-...  neutral\n",
      "4  C:\\Code\\Python\\data\\RAVDESS\\Actor_01\\03-01-03-...    happy\n",
      "\n",
      "Data Loading Complete.\n"
     ]
    }
   ],
   "source": [
    "# ## 2. Data Loading and Preparation\n",
    "# Loads audio file paths and emotion labels from the RAVDESS, CREMA-D,\n",
    "# and IEMOCAP datasets into a single Pandas DataFrame.\n",
    "# Ensures consistent labeling across datasets (e.g., maps 'exc' to 'happy').\n",
    "\n",
    "print(\"\\nStarting Data Loading...\")\n",
    "data = []\n",
    "iemocap_data = []\n",
    "\n",
    "# --- Process RAVDESS ---\n",
    "print(\"Processing RAVDESS...\")\n",
    "ravdess_map = {'01': 'neutral', '03': 'happy', '04': 'sad', '05': 'angry'}\n",
    "ravdess_count = 0\n",
    "for subdir, dirs, files in os.walk(ravdess_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.wav'):\n",
    "            try:\n",
    "                emotion_code = file.split('-')[2]\n",
    "                if emotion_code in ravdess_map:\n",
    "                    data.append({\n",
    "                        'file_path': os.path.join(subdir, file),\n",
    "                        'emotion': ravdess_map[emotion_code]\n",
    "                    })\n",
    "                    ravdess_count += 1\n",
    "            except IndexError:\n",
    "                print(f\"Skipping malformed RAVDESS filename: {file}\")\n",
    "print(f\"Found {ravdess_count} RAVDESS files.\")\n",
    "\n",
    "# --- Process CREMA-D ---\n",
    "print(\"\\nProcessing CREMA-D...\")\n",
    "crema_map = {'NEU': 'neutral', 'HAP': 'happy', 'SAD': 'sad', 'ANG': 'angry'}\n",
    "crema_count = 0\n",
    "for file in os.listdir(crema_d_path):\n",
    "    if file.endswith('.wav'):\n",
    "        try:\n",
    "            emotion_code = file.split('_')[2]\n",
    "            if emotion_code in crema_map:\n",
    "                data.append({\n",
    "                    'file_path': os.path.join(crema_d_path, file),\n",
    "                    'emotion': crema_map[emotion_code]\n",
    "                })\n",
    "                crema_count += 1\n",
    "        except IndexError:\n",
    "            print(f\"Skipping malformed CREMA-D filename: {file}\")\n",
    "print(f\"Found {crema_count} CREMA-D files.\")\n",
    "\n",
    "# --- Process IEMOCAP ---\n",
    "print(\"\\nProcessing IEMOCAP...\")\n",
    "iemocap_map = {'neu': 'neutral', 'hap': 'happy', 'sad': 'sad', 'ang': 'angry', 'exc': 'happy'}\n",
    "iemocap_count = 0\n",
    "for session in os.listdir(iemocap_path):\n",
    "    if session.startswith('Session'):\n",
    "        eval_path = os.path.join(iemocap_path, session, 'dialog/EmoEvaluation/')\n",
    "        if not os.path.isdir(eval_path): continue\n",
    "        for eval_file in os.listdir(eval_path):\n",
    "            if eval_file.endswith('.txt'):\n",
    "                try:\n",
    "                    with open(os.path.join(eval_path, eval_file), 'r') as f:\n",
    "                        for line in f:\n",
    "                            if line.strip().startswith('['):\n",
    "                                parts = line.split('\\t')\n",
    "                                if len(parts) >= 3:\n",
    "                                    utterance_id = parts[1]\n",
    "                                    emotion_code = parts[2]\n",
    "                                    if emotion_code in iemocap_map:\n",
    "                                        parent_folder = utterance_id.rsplit('_', 1)[0]\n",
    "                                        wav_path = os.path.join(iemocap_path, session, 'sentences/wav/', parent_folder, utterance_id + '.wav')\n",
    "                                        if os.path.exists(wav_path):\n",
    "                                            iemocap_data.append({\n",
    "                                                'file_path': wav_path,\n",
    "                                                'emotion': iemocap_map[emotion_code]\n",
    "                                            })\n",
    "                                            iemocap_count += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing IEMOCAP file {eval_file}: {e}\")\n",
    "print(f\"Found {iemocap_count} IEMOCAP files.\")\n",
    "\n",
    "# --- Combine DataFrames ---\n",
    "df_ravdess_crema = pd.DataFrame(data)\n",
    "df_iemocap = pd.DataFrame(iemocap_data)\n",
    "df = pd.concat([df_ravdess_crema, df_iemocap], ignore_index=True)\n",
    "\n",
    "print(f\"\\nTotal audio files from all datasets: {len(df)}\")\n",
    "print(\"\\nFinal emotion distribution:\")\n",
    "print(df['emotion'].value_counts())\n",
    "print(\"\\nFirst 5 rows of final data:\")\n",
    "print(df.head())\n",
    "print(\"\\nData Loading Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25e85c2-601b-4477-a5b0-fe2ab4f65e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Defining Feature Extraction Function...\n",
      "\n",
      "Extracting Linear Spectrograms for all files...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34ad40f54b4b4b7cbafa0052e924b8ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting Spectrograms:   0%|          | 0/11775 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 11775 files.\n",
      "Feature Extraction Complete.\n"
     ]
    }
   ],
   "source": [
    "# ## 3. Feature Extraction (Linear Spectrogram)\n",
    "# Defines the function to convert raw audio waves into Linear Spectrograms\n",
    "# (dB scale) with fixed dimensions, matching the processing logic intended\n",
    "# for the Flutter app. Applies this function to all audio files via pandas apply.\n",
    "\n",
    "print(\"\\nDefining Feature Extraction Function...\")\n",
    "# Define the CORRECT feature extractor for LINEAR spectrograms\n",
    "def get_linear_spectrogram(file_path, sr=SR, n_fft=N_FFT, hop_length=HOP_LENGTH, n_freq_bins=N_FREQ_BINS, max_pad_len=MAX_PAD_LEN):\n",
    "    try:\n",
    "        y, _ = librosa.load(file_path, sr=sr) # Load with target sample rate\n",
    "        stft = librosa.stft(y, n_fft=n_fft, hop_length=hop_length)\n",
    "\n",
    "        # Manually convert amplitude to dB (matches Flutter's logic)\n",
    "        stft_mag = np.abs(stft)\n",
    "        stft_db = 20 * np.log10(np.maximum(1e-6, stft_mag))\n",
    "\n",
    "        stft_db = stft_db[:n_freq_bins, :] # Keep only the required frequency bins\n",
    "\n",
    "        # Pad or truncate time axis\n",
    "        if stft_db.shape[1] > max_pad_len:\n",
    "            stft_db = stft_db[:, :max_pad_len]\n",
    "        else:\n",
    "            pad_width = max_pad_len - stft_db.shape[1]\n",
    "            min_val = np.min(stft_db) if stft_db.size > 0 else -80.0 # Use min value for padding\n",
    "            stft_db = np.pad(stft_db, pad_width=((0, 0), (0, pad_width)), mode='constant', constant_values=min_val)\n",
    "\n",
    "        return stft_db.astype(np.float32) # Ensure float32 for TensorFlow\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- Extract Features ---\n",
    "print(\"\\nExtracting Linear Spectrograms for all files...\")\n",
    "# Initialize tqdm for pandas apply\n",
    "tqdm.pandas(desc=\"Extracting Spectrograms\")\n",
    "# Apply the function with progress bar\n",
    "df['spectrogram'] = df['file_path'].progress_apply(get_linear_spectrogram)\n",
    "# Create a new DataFrame dropping rows where extraction failed\n",
    "df_processed = df.dropna(subset=['spectrogram'])\n",
    "failed_count = len(df) - len(df_processed)\n",
    "print(f\"\\nSuccessfully processed {len(df_processed)} files.\")\n",
    "if failed_count > 0:\n",
    "    print(f\"❌ Failed to process {failed_count} files.\")\n",
    "print(\"Feature Extraction Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fad324-4903-4a42-b02d-af8c8296fbd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing Data for Training...\n",
      "\n",
      "Input shape: (11775, 128, 130, 1)\n",
      "Output shape (one-hot): (11775, 4)\n",
      "Classes: [np.str_('angry'), np.str_('happy'), np.str_('neutral'), np.str_('sad')]\n",
      "\n",
      "Training samples: 9420\n",
      "Testing samples: 2355\n",
      "\n",
      "Class Weights: {0: np.float64(1.0675430643699002), 1: np.float64(0.8944170148120015), 2: np.float64(0.9853556485355649), 3: np.float64(1.074851665905979)}\n",
      "Data Preparation Complete.\n"
     ]
    }
   ],
   "source": [
    "# ## 4. Data Splitting, Encoding, and Class Weights\n",
    "# Prepares the spectrogram data and labels for model training.\n",
    "# Splits the data into stratified training and testing sets (80/20).\n",
    "# Encodes labels into numerical format (one-hot).\n",
    "# Calculates class weights based on the training set distribution to address imbalances.\n",
    "\n",
    "print(\"\\nPreparing Data for Training...\")\n",
    "# Prepare data arrays from the successfully processed DataFrame\n",
    "X = np.array(df_processed['spectrogram'].tolist())\n",
    "X = X[..., np.newaxis] # Add channel dimension -> (N, freq, time, 1)\n",
    "y = np.array(df_processed['emotion'].tolist())\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y_labels = le.fit_transform(y) # Integer labels\n",
    "y_encoded = to_categorical(y_labels) # One-hot encoded labels\n",
    "NUM_CLASSES = len(le.classes_)\n",
    "\n",
    "# Stratified Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded,\n",
    "    test_size=0.2,\n",
    "    random_state=SEED,\n",
    "    stratify=y_labels # Use integer labels for stratification\n",
    ")\n",
    "\n",
    "print(f\"\\nInput shape: {X.shape}\")\n",
    "print(f\"Output shape (one-hot): {y_encoded.shape}\")\n",
    "print(f\"Classes: {list(le.classes_)}\")\n",
    "print(f\"\\nTraining samples: {len(X_train)}\")\n",
    "print(f\"Testing samples: {len(X_test)}\")\n",
    "\n",
    "# Calculate Class Weights (using integer labels from the training split)\n",
    "y_train_labels = np.argmax(y_train, axis=1) # Convert one-hot back to integer labels\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced', # Automatically balance classes\n",
    "    classes=np.unique(y_train_labels),\n",
    "    y=y_train_labels\n",
    ")\n",
    "# Convert weights to a dictionary format expected by Keras\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "print(\"\\nClass Weights:\", class_weights_dict)\n",
    "print(\"Data Preparation Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2515129-8aaa-4409-b3fb-1bc116bea514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Defining Custom SpecAugment Layer...\n",
      "✅ Custom Layer Defined.\n"
     ]
    }
   ],
   "source": [
    "# ## 5. Custom SpecAugment Layer Definition\n",
    "# Defines a custom Keras layer for SpecAugment (frequency and time masking)\n",
    "# used for data augmentation during training. Includes necessary configuration\n",
    "# methods (`get_config`) and registration (`@keras.saving.register_keras_serializable()`)\n",
    "# for saving and loading the model correctly.\n",
    "\n",
    "print(\"\\nDefining Custom SpecAugment Layer...\")\n",
    "@keras.saving.register_keras_serializable()\n",
    "class SpecAugment(Layer):\n",
    "    def __init__(self, freq_mask_param, time_mask_param, **kwargs):\n",
    "        super(SpecAugment, self).__init__(**kwargs)\n",
    "        self.freq_mask_param = freq_mask_param\n",
    "        self.time_mask_param = time_mask_param\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        if not training:\n",
    "            return inputs # Augmentation is only applied during training\n",
    "\n",
    "        freq_max = tf.shape(inputs)[1] # Assuming shape is (batch, freq, time, ch)\n",
    "        f = tf.random.uniform(shape=(), minval=0, maxval=self.freq_mask_param, dtype=tf.int32)\n",
    "        f0 = tf.random.uniform(shape=(), minval=0, maxval=freq_max - f, dtype=tf.int32)\n",
    "        # Create frequency mask\n",
    "        mask_f_before = tf.ones((f0, tf.shape(inputs)[2]))\n",
    "        mask_f_zero = tf.zeros((f, tf.shape(inputs)[2]))\n",
    "        mask_f_after = tf.ones((freq_max - f0 - f, tf.shape(inputs)[2]))\n",
    "        mask_f = tf.concat([mask_f_before, mask_f_zero, mask_f_after], axis=0)\n",
    "\n",
    "        time_max = tf.shape(inputs)[2]\n",
    "        t = tf.random.uniform(shape=(), minval=0, maxval=self.time_mask_param, dtype=tf.int32)\n",
    "        t0 = tf.random.uniform(shape=(), minval=0, maxval=time_max - t, dtype=tf.int32)\n",
    "        # Create time mask\n",
    "        mask_t_before = tf.ones((tf.shape(inputs)[1], t0))\n",
    "        mask_t_zero = tf.zeros((tf.shape(inputs)[1], t))\n",
    "        mask_t_after = tf.ones((tf.shape(inputs)[1], time_max - t0 - t))\n",
    "        mask_t = tf.concat([mask_t_before, mask_t_zero, mask_t_after], axis=1)\n",
    "\n",
    "        # Expand masks to match input dimensions and apply\n",
    "        mask_f = mask_f[..., tf.newaxis] # Add channel dim\n",
    "        mask_t = mask_t[..., tf.newaxis] # Add channel dim\n",
    "\n",
    "        # Apply masks element-wise\n",
    "        augmented = inputs * mask_f # Frequency masking\n",
    "        augmented = augmented * mask_t # Time masking\n",
    "        return augmented\n",
    "\n",
    "    # get_config is crucial for saving and loading the model\n",
    "    def get_config(self):\n",
    "        config = super(SpecAugment, self).get_config()\n",
    "        config.update({\n",
    "            \"freq_mask_param\": self.freq_mask_param,\n",
    "            \"time_mask_param\": self.time_mask_param,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "print(\"✅ Custom Layer Defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89243772-c076-4a20-b2a4-2adace990475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building CRNN Model...\n",
      "WARNING:tensorflow:From C:\\Users\\xrist\\miniconda3\\envs\\ser_final\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ## 6. Build the CRNN Model Architecture\n",
    "# Defines the Convolutional Recurrent Neural Network (CRNN) model.\n",
    "# Includes data augmentation (GaussianNoise, SpecAugment), multiple CNN blocks\n",
    "# for feature extraction, reshaping, Bidirectional LSTMs for sequence modeling,\n",
    "# and Dense layers for final classification. Strong regularization (Dropout,\n",
    "# BatchNormalization) is used throughout.\n",
    "\n",
    "print(\"\\nBuilding CRNN Model...\")\n",
    "INPUT_SHAPE = (X_train.shape[1], X_train.shape[2], 1) # Should be (128, 130, 1)\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=INPUT_SHAPE, name='input_spectrogram'),\n",
    "    GaussianNoise(0.1, name='noise'),\n",
    "    SpecAugment(freq_mask_param=15, time_mask_param=30, name='spec_augment'),\n",
    "\n",
    "    # CNN Block 1\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same', name='conv1'),\n",
    "    BatchNormalization(name='bn1'),\n",
    "    MaxPooling2D((2, 2), name='pool1'),\n",
    "    Dropout(0.2, name='drop1'),\n",
    "\n",
    "    # CNN Block 2\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same', name='conv2'),\n",
    "    BatchNormalization(name='bn2'),\n",
    "    MaxPooling2D((2, 2), name='pool2'),\n",
    "    Dropout(0.2, name='drop2'),\n",
    "\n",
    "    # CNN Block 3\n",
    "    Conv2D(256, (3, 3), activation='relu', padding='same', name='conv3'),\n",
    "    BatchNormalization(name='bn3'),\n",
    "    MaxPooling2D((2, 2), name='pool3'),\n",
    "    Dropout(0.3, name='drop3'),\n",
    "\n",
    "    # CNN Block 4\n",
    "    Conv2D(256, (3, 3), activation='relu', padding='same', name='conv4'),\n",
    "    BatchNormalization(name='bn4'),\n",
    "    MaxPooling2D((2, 2), name='pool4'),\n",
    "    Dropout(0.3, name='drop4'),\n",
    "\n",
    "    # Reshape for RNN: (batch, time, features)\n",
    "    # After 4 pooling layers with pool_size=(2,2), the dimensions become:\n",
    "    # Freq: 128 / 16 = 8\n",
    "    # Time: 130 / 16 = 8 (integer division)\n",
    "    # Channels: 256\n",
    "    # Reshape to (batch, time_steps=8, features=8*256)\n",
    "    Reshape((8, 8 * 256), name='reshape_for_rnn'),\n",
    "\n",
    "    # RNN Blocks (Bidirectional LSTMs)\n",
    "    Bidirectional(LSTM(128, return_sequences=True), name='bilstm1'),\n",
    "    Dropout(0.4, name='drop_rnn1'),\n",
    "\n",
    "    Bidirectional(LSTM(64), name='bilstm2'),\n",
    "    Dropout(0.4, name='drop_rnn2'),\n",
    "\n",
    "    # Dense Layers\n",
    "    Dense(256, activation='relu', name='dense1'),\n",
    "    BatchNormalization(name='bn_dense1'),\n",
    "    Dropout(0.5, name='drop_dense1'),\n",
    "\n",
    "    Dense(128, activation='relu', name='dense2'),\n",
    "    BatchNormalization(name='bn_dense2'),\n",
    "    Dropout(0.5, name='drop_dense2'),\n",
    "\n",
    "    Dense(NUM_CLASSES, activation='softmax', name='output')\n",
    "], name=\"CRNN_Emotion_Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e94139-f6dc-4d5e-9587-aada505ee1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Compiling Model and Defining Callbacks...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"CRNN_Emotion_Model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"CRNN_Emotion_Model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ noise (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GaussianNoise</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ spec_augment (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpecAugment</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bn1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ pool1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ drop1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bn2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ pool2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ drop2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bn3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ pool3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ drop3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bn4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ pool4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ drop4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ reshape_for_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bilstm1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,229,248</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ drop_rnn1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bilstm2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">164,352</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ drop_rnn2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bn_dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ drop_dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bn_dense2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ drop_dense2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ noise (\u001b[38;5;33mGaussianNoise\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ spec_augment (\u001b[38;5;33mSpecAugment\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1 (\u001b[38;5;33mConv2D\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m640\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bn1 (\u001b[38;5;33mBatchNormalization\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m256\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ pool1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ drop1 (\u001b[38;5;33mDropout\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2 (\u001b[38;5;33mConv2D\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │          \u001b[38;5;34m73,856\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bn2 (\u001b[38;5;33mBatchNormalization\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m512\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ pool2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ drop2 (\u001b[38;5;33mDropout\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv3 (\u001b[38;5;33mConv2D\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m295,168\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bn3 (\u001b[38;5;33mBatchNormalization\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │           \u001b[38;5;34m1,024\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ pool3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ drop3 (\u001b[38;5;33mDropout\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv4 (\u001b[38;5;33mConv2D\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m590,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bn4 (\u001b[38;5;33mBatchNormalization\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │           \u001b[38;5;34m1,024\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ pool4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ drop4 (\u001b[38;5;33mDropout\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ reshape_for_rnn (\u001b[38;5;33mReshape\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m2048\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bilstm1 (\u001b[38;5;33mBidirectional\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │       \u001b[38;5;34m2,229,248\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ drop_rnn1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bilstm2 (\u001b[38;5;33mBidirectional\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m164,352\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ drop_rnn2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense1 (\u001b[38;5;33mDense\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │          \u001b[38;5;34m33,024\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bn_dense1 (\u001b[38;5;33mBatchNormalization\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │           \u001b[38;5;34m1,024\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ drop_dense1 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense2 (\u001b[38;5;33mDense\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m32,896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bn_dense2 (\u001b[38;5;33mBatchNormalization\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ drop_dense2 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │             \u001b[38;5;34m516\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,424,132</span> (13.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,424,132\u001b[0m (13.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,421,956</span> (13.05 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,421,956\u001b[0m (13.05 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,176</span> (8.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,176\u001b[0m (8.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model Compiled and Callbacks Defined.\n"
     ]
    }
   ],
   "source": [
    "# ## 7. Compile Model and Define Callbacks\n",
    "# Compiles the CRNN model using the Adam optimizer with a low learning rate,\n",
    "# categorical cross-entropy loss (suitable for multi-class classification),\n",
    "# and accuracy as the evaluation metric. Defines callbacks for training:\n",
    "# - EarlyStopping: Stops training if validation loss doesn't improve.\n",
    "# - ReduceLROnPlateau: Reduces learning rate if validation accuracy plateaus.\n",
    "# - ModelCheckpoint: Saves the best performing model based on validation accuracy.\n",
    "\n",
    "print(\"\\nCompiling Model and Defining Callbacks...\")\n",
    "# Compile with a lower initial learning rate and Adam optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define callbacks\n",
    "early_stop = EarlyStopping(patience=20, monitor='val_loss', restore_best_weights=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=5, min_lr=0.000001, verbose=1)\n",
    "# Define checkpoint path\n",
    "checkpoint_filepath = 'best_crnn_model.keras'\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True, # Only save the best model\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "print(\"✅ Model Compiled and Callbacks Defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc95c8f5-d9d6-47fe-b70e-cf8e6ba017c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Starting CRNN Training...\n",
      "Epoch 1/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715ms/step - accuracy: 0.3023 - loss: 2.1323\n",
      "Epoch 1: val_accuracy improved from -inf to 0.38429, saving model to best_crnn_model.keras\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 760ms/step - accuracy: 0.3025 - loss: 2.1319 - val_accuracy: 0.3843 - val_loss: 1.4953 - learning_rate: 1.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670ms/step - accuracy: 0.3678 - loss: 1.8214\n",
      "Epoch 2: val_accuracy improved from 0.38429 to 0.41614, saving model to best_crnn_model.keras\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 709ms/step - accuracy: 0.3679 - loss: 1.8213 - val_accuracy: 0.4161 - val_loss: 1.4780 - learning_rate: 1.0000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646ms/step - accuracy: 0.3799 - loss: 1.6894\n",
      "Epoch 3: val_accuracy improved from 0.41614 to 0.42335, saving model to best_crnn_model.keras\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 684ms/step - accuracy: 0.3800 - loss: 1.6893 - val_accuracy: 0.4234 - val_loss: 1.3714 - learning_rate: 1.0000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637ms/step - accuracy: 0.3861 - loss: 1.6200\n",
      "Epoch 4: val_accuracy improved from 0.42335 to 0.43142, saving model to best_crnn_model.keras\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 675ms/step - accuracy: 0.3861 - loss: 1.6198 - val_accuracy: 0.4314 - val_loss: 1.3048 - learning_rate: 1.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649ms/step - accuracy: 0.4018 - loss: 1.4954\n",
      "Epoch 5: val_accuracy improved from 0.43142 to 0.43397, saving model to best_crnn_model.keras\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 686ms/step - accuracy: 0.4018 - loss: 1.4953 - val_accuracy: 0.4340 - val_loss: 1.2096 - learning_rate: 1.0000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631ms/step - accuracy: 0.4084 - loss: 1.4476\n",
      "Epoch 6: val_accuracy improved from 0.43397 to 0.44204, saving model to best_crnn_model.keras\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 668ms/step - accuracy: 0.4084 - loss: 1.4475 - val_accuracy: 0.4420 - val_loss: 1.1976 - learning_rate: 1.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609ms/step - accuracy: 0.4217 - loss: 1.3786\n",
      "Epoch 7: val_accuracy improved from 0.44204 to 0.48960, saving model to best_crnn_model.keras\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 646ms/step - accuracy: 0.4217 - loss: 1.3786 - val_accuracy: 0.4896 - val_loss: 1.1156 - learning_rate: 1.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599ms/step - accuracy: 0.4397 - loss: 1.3188\n",
      "Epoch 8: val_accuracy did not improve from 0.48960\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 633ms/step - accuracy: 0.4397 - loss: 1.3188 - val_accuracy: 0.4841 - val_loss: 1.1002 - learning_rate: 1.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601ms/step - accuracy: 0.4388 - loss: 1.2922\n",
      "Epoch 9: val_accuracy improved from 0.48960 to 0.50276, saving model to best_crnn_model.keras\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 637ms/step - accuracy: 0.4388 - loss: 1.2922 - val_accuracy: 0.5028 - val_loss: 1.0838 - learning_rate: 1.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598ms/step - accuracy: 0.4391 - loss: 1.2652\n",
      "Epoch 10: val_accuracy did not improve from 0.50276\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 633ms/step - accuracy: 0.4391 - loss: 1.2651 - val_accuracy: 0.4977 - val_loss: 1.1104 - learning_rate: 1.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589ms/step - accuracy: 0.4555 - loss: 1.2161\n",
      "Epoch 11: val_accuracy did not improve from 0.50276\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 624ms/step - accuracy: 0.4555 - loss: 1.2160 - val_accuracy: 0.4989 - val_loss: 1.0847 - learning_rate: 1.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587ms/step - accuracy: 0.4539 - loss: 1.2066\n",
      "Epoch 12: val_accuracy improved from 0.50276 to 0.50318, saving model to best_crnn_model.keras\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 622ms/step - accuracy: 0.4539 - loss: 1.2065 - val_accuracy: 0.5032 - val_loss: 1.0957 - learning_rate: 1.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587ms/step - accuracy: 0.4701 - loss: 1.1745\n",
      "Epoch 13: val_accuracy did not improve from 0.50318\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 620ms/step - accuracy: 0.4701 - loss: 1.1745 - val_accuracy: 0.5032 - val_loss: 1.1060 - learning_rate: 1.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585ms/step - accuracy: 0.4814 - loss: 1.1522\n",
      "Epoch 14: val_accuracy improved from 0.50318 to 0.53163, saving model to best_crnn_model.keras\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 620ms/step - accuracy: 0.4814 - loss: 1.1522 - val_accuracy: 0.5316 - val_loss: 1.0649 - learning_rate: 1.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592ms/step - accuracy: 0.4817 - loss: 1.1442\n",
      "Epoch 15: val_accuracy did not improve from 0.53163\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 626ms/step - accuracy: 0.4817 - loss: 1.1442 - val_accuracy: 0.5151 - val_loss: 1.1413 - learning_rate: 1.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585ms/step - accuracy: 0.4895 - loss: 1.1141\n",
      "Epoch 16: val_accuracy did not improve from 0.53163\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 619ms/step - accuracy: 0.4895 - loss: 1.1141 - val_accuracy: 0.4858 - val_loss: 1.1530 - learning_rate: 1.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584ms/step - accuracy: 0.5044 - loss: 1.0986\n",
      "Epoch 17: val_accuracy improved from 0.53163 to 0.53376, saving model to best_crnn_model.keras\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 618ms/step - accuracy: 0.5044 - loss: 1.0986 - val_accuracy: 0.5338 - val_loss: 1.0619 - learning_rate: 1.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585ms/step - accuracy: 0.5031 - loss: 1.0903\n",
      "Epoch 18: val_accuracy did not improve from 0.53376\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 619ms/step - accuracy: 0.5031 - loss: 1.0903 - val_accuracy: 0.5244 - val_loss: 1.0578 - learning_rate: 1.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584ms/step - accuracy: 0.4968 - loss: 1.0855\n",
      "Epoch 19: val_accuracy did not improve from 0.53376\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 617ms/step - accuracy: 0.4968 - loss: 1.0855 - val_accuracy: 0.4917 - val_loss: 1.1519 - learning_rate: 1.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583ms/step - accuracy: 0.5238 - loss: 1.0705\n",
      "Epoch 20: val_accuracy improved from 0.53376 to 0.53970, saving model to best_crnn_model.keras\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 617ms/step - accuracy: 0.5238 - loss: 1.0705 - val_accuracy: 0.5397 - val_loss: 1.0405 - learning_rate: 1.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582ms/step - accuracy: 0.5181 - loss: 1.0610\n",
      "Epoch 21: val_accuracy improved from 0.53970 to 0.55456, saving model to best_crnn_model.keras\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 616ms/step - accuracy: 0.5181 - loss: 1.0610 - val_accuracy: 0.5546 - val_loss: 1.0052 - learning_rate: 1.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579ms/step - accuracy: 0.5202 - loss: 1.0554\n",
      "Epoch 22: val_accuracy did not improve from 0.55456\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 612ms/step - accuracy: 0.5202 - loss: 1.0554 - val_accuracy: 0.5333 - val_loss: 1.0523 - learning_rate: 1.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577ms/step - accuracy: 0.5215 - loss: 1.0525\n",
      "Epoch 23: val_accuracy did not improve from 0.55456\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 610ms/step - accuracy: 0.5215 - loss: 1.0525 - val_accuracy: 0.5431 - val_loss: 1.0132 - learning_rate: 1.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577ms/step - accuracy: 0.5340 - loss: 1.0286\n",
      "Epoch 24: val_accuracy did not improve from 0.55456\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 610ms/step - accuracy: 0.5340 - loss: 1.0286 - val_accuracy: 0.5537 - val_loss: 0.9931 - learning_rate: 1.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584ms/step - accuracy: 0.5339 - loss: 1.0185\n",
      "Epoch 25: val_accuracy did not improve from 0.55456\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 617ms/step - accuracy: 0.5339 - loss: 1.0185 - val_accuracy: 0.5363 - val_loss: 1.0371 - learning_rate: 1.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575ms/step - accuracy: 0.5457 - loss: 1.0154\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 26: val_accuracy did not improve from 0.55456\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 608ms/step - accuracy: 0.5457 - loss: 1.0154 - val_accuracy: 0.5507 - val_loss: 1.0067 - learning_rate: 1.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578ms/step - accuracy: 0.5530 - loss: 1.0039\n",
      "Epoch 27: val_accuracy did not improve from 0.55456\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 611ms/step - accuracy: 0.5530 - loss: 1.0039 - val_accuracy: 0.5499 - val_loss: 0.9893 - learning_rate: 5.0000e-05\n",
      "Epoch 28/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578ms/step - accuracy: 0.5460 - loss: 1.0052\n",
      "Epoch 28: val_accuracy improved from 0.55456 to 0.56306, saving model to best_crnn_model.keras\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 613ms/step - accuracy: 0.5461 - loss: 1.0051 - val_accuracy: 0.5631 - val_loss: 0.9698 - learning_rate: 5.0000e-05\n",
      "Epoch 29/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574ms/step - accuracy: 0.5578 - loss: 0.9792\n",
      "Epoch 29: val_accuracy improved from 0.56306 to 0.57028, saving model to best_crnn_model.keras\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 609ms/step - accuracy: 0.5578 - loss: 0.9792 - val_accuracy: 0.5703 - val_loss: 0.9654 - learning_rate: 5.0000e-05\n",
      "Epoch 30/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572ms/step - accuracy: 0.5648 - loss: 0.9773\n",
      "Epoch 30: val_accuracy did not improve from 0.57028\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 606ms/step - accuracy: 0.5648 - loss: 0.9773 - val_accuracy: 0.5626 - val_loss: 0.9700 - learning_rate: 5.0000e-05\n",
      "Epoch 31/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570ms/step - accuracy: 0.5651 - loss: 0.9723\n",
      "Epoch 31: val_accuracy did not improve from 0.57028\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 603ms/step - accuracy: 0.5651 - loss: 0.9723 - val_accuracy: 0.5406 - val_loss: 1.0075 - learning_rate: 5.0000e-05\n",
      "Epoch 32/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571ms/step - accuracy: 0.5637 - loss: 0.9841\n",
      "Epoch 32: val_accuracy did not improve from 0.57028\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 603ms/step - accuracy: 0.5637 - loss: 0.9840 - val_accuracy: 0.5643 - val_loss: 0.9787 - learning_rate: 5.0000e-05\n",
      "Epoch 33/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568ms/step - accuracy: 0.5743 - loss: 0.9631\n",
      "Epoch 33: val_accuracy did not improve from 0.57028\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 601ms/step - accuracy: 0.5743 - loss: 0.9631 - val_accuracy: 0.5495 - val_loss: 0.9884 - learning_rate: 5.0000e-05\n",
      "Epoch 34/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569ms/step - accuracy: 0.5624 - loss: 0.9673\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 34: val_accuracy did not improve from 0.57028\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 602ms/step - accuracy: 0.5624 - loss: 0.9673 - val_accuracy: 0.5682 - val_loss: 0.9494 - learning_rate: 5.0000e-05\n",
      "Epoch 35/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564ms/step - accuracy: 0.5791 - loss: 0.9576\n",
      "Epoch 35: val_accuracy improved from 0.57028 to 0.57155, saving model to best_crnn_model.keras\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 597ms/step - accuracy: 0.5791 - loss: 0.9575 - val_accuracy: 0.5715 - val_loss: 0.9666 - learning_rate: 2.5000e-05\n",
      "Epoch 36/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567ms/step - accuracy: 0.5764 - loss: 0.9514\n",
      "Epoch 36: val_accuracy improved from 0.57155 to 0.57877, saving model to best_crnn_model.keras\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 600ms/step - accuracy: 0.5764 - loss: 0.9514 - val_accuracy: 0.5788 - val_loss: 0.9580 - learning_rate: 2.5000e-05\n",
      "Epoch 37/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564ms/step - accuracy: 0.5848 - loss: 0.9503\n",
      "Epoch 37: val_accuracy improved from 0.57877 to 0.58004, saving model to best_crnn_model.keras\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 598ms/step - accuracy: 0.5848 - loss: 0.9503 - val_accuracy: 0.5800 - val_loss: 0.9483 - learning_rate: 2.5000e-05\n",
      "Epoch 38/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564ms/step - accuracy: 0.5888 - loss: 0.9332\n",
      "Epoch 38: val_accuracy did not improve from 0.58004\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 597ms/step - accuracy: 0.5888 - loss: 0.9332 - val_accuracy: 0.5656 - val_loss: 1.0007 - learning_rate: 2.5000e-05\n",
      "Epoch 39/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569ms/step - accuracy: 0.5814 - loss: 0.9312\n",
      "Epoch 39: val_accuracy did not improve from 0.58004\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 601ms/step - accuracy: 0.5814 - loss: 0.9311 - val_accuracy: 0.5749 - val_loss: 0.9656 - learning_rate: 2.5000e-05\n",
      "Epoch 40/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569ms/step - accuracy: 0.5835 - loss: 0.9338\n",
      "Epoch 40: val_accuracy improved from 0.58004 to 0.58896, saving model to best_crnn_model.keras\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 602ms/step - accuracy: 0.5835 - loss: 0.9338 - val_accuracy: 0.5890 - val_loss: 0.9510 - learning_rate: 2.5000e-05\n",
      "Epoch 41/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568ms/step - accuracy: 0.5925 - loss: 0.9299\n",
      "Epoch 41: val_accuracy improved from 0.58896 to 0.59023, saving model to best_crnn_model.keras\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 601ms/step - accuracy: 0.5925 - loss: 0.9299 - val_accuracy: 0.5902 - val_loss: 0.9444 - learning_rate: 2.5000e-05\n",
      "Epoch 42/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563ms/step - accuracy: 0.5916 - loss: 0.9289\n",
      "Epoch 42: val_accuracy improved from 0.59023 to 0.59193, saving model to best_crnn_model.keras\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 597ms/step - accuracy: 0.5916 - loss: 0.9289 - val_accuracy: 0.5919 - val_loss: 0.9421 - learning_rate: 2.5000e-05\n",
      "Epoch 43/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564ms/step - accuracy: 0.5995 - loss: 0.9211\n",
      "Epoch 43: val_accuracy did not improve from 0.59193\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 596ms/step - accuracy: 0.5995 - loss: 0.9211 - val_accuracy: 0.5834 - val_loss: 0.9467 - learning_rate: 2.5000e-05\n",
      "Epoch 44/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565ms/step - accuracy: 0.5961 - loss: 0.9144\n",
      "Epoch 44: val_accuracy did not improve from 0.59193\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 598ms/step - accuracy: 0.5962 - loss: 0.9144 - val_accuracy: 0.5758 - val_loss: 0.9625 - learning_rate: 2.5000e-05\n",
      "Epoch 45/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563ms/step - accuracy: 0.6076 - loss: 0.9125\n",
      "Epoch 45: val_accuracy did not improve from 0.59193\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 596ms/step - accuracy: 0.6076 - loss: 0.9124 - val_accuracy: 0.5775 - val_loss: 0.9605 - learning_rate: 2.5000e-05\n",
      "Epoch 46/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564ms/step - accuracy: 0.6009 - loss: 0.9147\n",
      "Epoch 46: val_accuracy improved from 0.59193 to 0.59448, saving model to best_crnn_model.keras\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 598ms/step - accuracy: 0.6009 - loss: 0.9146 - val_accuracy: 0.5945 - val_loss: 0.9370 - learning_rate: 2.5000e-05\n",
      "Epoch 47/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563ms/step - accuracy: 0.6044 - loss: 0.9159\n",
      "Epoch 47: val_accuracy did not improve from 0.59448\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 595ms/step - accuracy: 0.6044 - loss: 0.9159 - val_accuracy: 0.5928 - val_loss: 0.9397 - learning_rate: 2.5000e-05\n",
      "Epoch 48/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561ms/step - accuracy: 0.6131 - loss: 0.8983\n",
      "Epoch 48: val_accuracy improved from 0.59448 to 0.60425, saving model to best_crnn_model.keras\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 594ms/step - accuracy: 0.6131 - loss: 0.8983 - val_accuracy: 0.6042 - val_loss: 0.9242 - learning_rate: 2.5000e-05\n",
      "Epoch 49/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567ms/step - accuracy: 0.6115 - loss: 0.8922\n",
      "Epoch 49: val_accuracy did not improve from 0.60425\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 599ms/step - accuracy: 0.6115 - loss: 0.8921 - val_accuracy: 0.5902 - val_loss: 0.9412 - learning_rate: 2.5000e-05\n",
      "Epoch 50/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566ms/step - accuracy: 0.6092 - loss: 0.8981\n",
      "Epoch 50: val_accuracy did not improve from 0.60425\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 599ms/step - accuracy: 0.6093 - loss: 0.8981 - val_accuracy: 0.5877 - val_loss: 0.9584 - learning_rate: 2.5000e-05\n",
      "Epoch 51/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564ms/step - accuracy: 0.6070 - loss: 0.8877\n",
      "Epoch 51: val_accuracy did not improve from 0.60425\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 596ms/step - accuracy: 0.6070 - loss: 0.8877 - val_accuracy: 0.5983 - val_loss: 0.9326 - learning_rate: 2.5000e-05\n",
      "Epoch 52/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564ms/step - accuracy: 0.6176 - loss: 0.8849\n",
      "Epoch 52: val_accuracy did not improve from 0.60425\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 597ms/step - accuracy: 0.6176 - loss: 0.8849 - val_accuracy: 0.5898 - val_loss: 0.9732 - learning_rate: 2.5000e-05\n",
      "Epoch 53/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562ms/step - accuracy: 0.6206 - loss: 0.8795\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 53: val_accuracy did not improve from 0.60425\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 595ms/step - accuracy: 0.6206 - loss: 0.8795 - val_accuracy: 0.5992 - val_loss: 0.9407 - learning_rate: 2.5000e-05\n",
      "Epoch 54/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564ms/step - accuracy: 0.6238 - loss: 0.8738\n",
      "Epoch 54: val_accuracy did not improve from 0.60425\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 596ms/step - accuracy: 0.6238 - loss: 0.8738 - val_accuracy: 0.5822 - val_loss: 0.9696 - learning_rate: 1.2500e-05\n",
      "Epoch 55/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564ms/step - accuracy: 0.6249 - loss: 0.8695\n",
      "Epoch 55: val_accuracy did not improve from 0.60425\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 596ms/step - accuracy: 0.6249 - loss: 0.8695 - val_accuracy: 0.6017 - val_loss: 0.9344 - learning_rate: 1.2500e-05\n",
      "Epoch 56/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563ms/step - accuracy: 0.6320 - loss: 0.8602\n",
      "Epoch 56: val_accuracy did not improve from 0.60425\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 595ms/step - accuracy: 0.6320 - loss: 0.8602 - val_accuracy: 0.6017 - val_loss: 0.9383 - learning_rate: 1.2500e-05\n",
      "Epoch 57/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562ms/step - accuracy: 0.6332 - loss: 0.8571\n",
      "Epoch 57: val_accuracy did not improve from 0.60425\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 595ms/step - accuracy: 0.6332 - loss: 0.8571 - val_accuracy: 0.5975 - val_loss: 0.9384 - learning_rate: 1.2500e-05\n",
      "Epoch 58/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563ms/step - accuracy: 0.6326 - loss: 0.8588\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 58: val_accuracy did not improve from 0.60425\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 595ms/step - accuracy: 0.6326 - loss: 0.8588 - val_accuracy: 0.5992 - val_loss: 0.9300 - learning_rate: 1.2500e-05\n",
      "Epoch 59/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564ms/step - accuracy: 0.6201 - loss: 0.8704\n",
      "Epoch 59: val_accuracy did not improve from 0.60425\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 597ms/step - accuracy: 0.6202 - loss: 0.8704 - val_accuracy: 0.5966 - val_loss: 0.9436 - learning_rate: 6.2500e-06\n",
      "Epoch 60/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561ms/step - accuracy: 0.6315 - loss: 0.8643\n",
      "Epoch 60: val_accuracy did not improve from 0.60425\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 594ms/step - accuracy: 0.6315 - loss: 0.8643 - val_accuracy: 0.5983 - val_loss: 0.9428 - learning_rate: 6.2500e-06\n",
      "Epoch 61/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562ms/step - accuracy: 0.6376 - loss: 0.8651\n",
      "Epoch 61: val_accuracy did not improve from 0.60425\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 594ms/step - accuracy: 0.6376 - loss: 0.8651 - val_accuracy: 0.6008 - val_loss: 0.9314 - learning_rate: 6.2500e-06\n",
      "Epoch 62/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563ms/step - accuracy: 0.6381 - loss: 0.8467\n",
      "Epoch 62: val_accuracy did not improve from 0.60425\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 596ms/step - accuracy: 0.6381 - loss: 0.8467 - val_accuracy: 0.5949 - val_loss: 0.9348 - learning_rate: 6.2500e-06\n",
      "Epoch 63/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561ms/step - accuracy: 0.6393 - loss: 0.8510\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 63: val_accuracy did not improve from 0.60425\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 593ms/step - accuracy: 0.6393 - loss: 0.8510 - val_accuracy: 0.5941 - val_loss: 0.9399 - learning_rate: 6.2500e-06\n",
      "Epoch 64/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561ms/step - accuracy: 0.6412 - loss: 0.8509\n",
      "Epoch 64: val_accuracy did not improve from 0.60425\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 594ms/step - accuracy: 0.6412 - loss: 0.8509 - val_accuracy: 0.5983 - val_loss: 0.9326 - learning_rate: 3.1250e-06\n",
      "Epoch 65/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562ms/step - accuracy: 0.6375 - loss: 0.8463\n",
      "Epoch 65: val_accuracy did not improve from 0.60425\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 595ms/step - accuracy: 0.6375 - loss: 0.8463 - val_accuracy: 0.5979 - val_loss: 0.9308 - learning_rate: 3.1250e-06\n",
      "Epoch 66/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564ms/step - accuracy: 0.6451 - loss: 0.8420\n",
      "Epoch 66: val_accuracy did not improve from 0.60425\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 596ms/step - accuracy: 0.6451 - loss: 0.8420 - val_accuracy: 0.6008 - val_loss: 0.9315 - learning_rate: 3.1250e-06\n",
      "Epoch 67/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560ms/step - accuracy: 0.6332 - loss: 0.8504\n",
      "Epoch 67: val_accuracy did not improve from 0.60425\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 592ms/step - accuracy: 0.6333 - loss: 0.8504 - val_accuracy: 0.6025 - val_loss: 0.9322 - learning_rate: 3.1250e-06\n",
      "Epoch 68/100\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562ms/step - accuracy: 0.6428 - loss: 0.8573\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 68: val_accuracy did not improve from 0.60425\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 595ms/step - accuracy: 0.6428 - loss: 0.8573 - val_accuracy: 0.6017 - val_loss: 0.9312 - learning_rate: 3.1250e-06\n",
      "Epoch 68: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "\n",
      "✅ Training Complete.\n"
     ]
    }
   ],
   "source": [
    "# ## 8. Train the Model\n",
    "# Trains the compiled CRNN model using the prepared training data.\n",
    "# Uses the defined callbacks to manage the training process, apply class weights\n",
    "# to handle imbalances, and validates performance on the test set after each epoch.\n",
    "# Note: This step is computationally intensive and will take a long time.\n",
    "\n",
    "print(\"\\n🚀 Starting CRNN Training...\")\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100, # Set a high number; EarlyStopping will find the optimal point\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[early_stop, reduce_lr, model_checkpoint],\n",
    "    class_weight=class_weights_dict, # Use class weights to address imbalance\n",
    "    verbose=1\n",
    ")\n",
    "print(\"\\n✅ Training Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c599ede6-d236-4c49-89c1-a6eae583b1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading best model weights from checkpoint...\n",
      "✅ Best model loaded successfully.\n",
      "\n",
      "Evaluating the best model on the test set...\n",
      "\n",
      "--- Final Best CRNN Model Accuracy: 60.42% ---\n",
      "❌ Error loading or evaluating the best model: No module named 'seaborn'\n",
      "Evaluation skipped.\n"
     ]
    }
   ],
   "source": [
    "# ## 9. Load Best Model and Evaluate\n",
    "# Loads the best model weights saved by the ModelCheckpoint callback during training.\n",
    "# Evaluates this best model on the unseen test set to get the final performance metrics.\n",
    "# Displays the final test accuracy, a detailed classification report (precision, recall, F1-score per class),\n",
    "# and a confusion matrix visualizing the model's predictions vs. true labels.\n",
    "\n",
    "print(\"\\nLoading best model weights from checkpoint...\")\n",
    "# Load the best performing model saved during training\n",
    "# Ensure custom objects are passed for the custom SpecAugment layer\n",
    "try:\n",
    "    # Load the model saved by ModelCheckpoint\n",
    "    model = keras.models.load_model(\n",
    "        checkpoint_filepath, # Use the path defined earlier\n",
    "        custom_objects={'SpecAugment': SpecAugment}\n",
    "    )\n",
    "    print(f\"✅ Best model loaded successfully from '{checkpoint_filepath}'.\")\n",
    "\n",
    "    # Evaluate the loaded best model\n",
    "    print(\"\\nEvaluating the best model on the test set...\")\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"\\n--- Final Best CRNN Model Accuracy: {accuracy*100:.2f}% ---\")\n",
    "\n",
    "    # Display Classification Report and Confusion Matrix\n",
    "    print(\"\\nGenerating evaluation plots...\")\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_true_classes = np.argmax(y_test, axis=1) # Convert one-hot back to integer labels\n",
    "\n",
    "    print(\"\\n📋 Classification Report:\")\n",
    "    # Use digits=3 for more precision in the report\n",
    "    print(classification_report(y_true_classes, y_pred_classes, target_names=le.classes_, digits=3))\n",
    "\n",
    "    # Plot Confusion Matrix\n",
    "    cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "    plt.title('Confusion Matrix for Best Model')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading or evaluating the best model from {checkpoint_filepath}: {e}\")\n",
    "    print(\"Evaluation skipped. Ensure training ran successfully and saved the checkpoint.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83e5ffa-40eb-49b4-831a-3501fc10159b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 10. Save Final Model for Server\n",
    "# Saves the final, best-performing model (loaded from the checkpoint)\n",
    "# in the Keras native format (`.keras`). This file contains the model architecture,\n",
    "# weights, and optimizer state, ready to be loaded by the Python Flask server (`server.py`).\n",
    "\n",
    "print(\"\\nSaving final best model for the server...\")\n",
    "try:\n",
    "    # Save the currently loaded best model\n",
    "    final_model_path = 'unbiased_app_model.keras'\n",
    "    model.save(final_model_path)\n",
    "    print(f\"✅ Final unbiased model saved as '{final_model_path}' for the server.\")\n",
    "    print(\"\\n🎉 ALL DONE! Your model is ready to use in server.py.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error saving the final Keras model: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Final SER Project)",
   "language": "python",
   "name": "ser_final"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
